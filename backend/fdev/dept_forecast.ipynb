{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41acc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll provide a demo that the user can run with their actual CSV.\n",
    "# This cell creates a small synthetic dataset to demonstrate the visualization\n",
    "# and defines a reusable function `plot_avg_grades_by_department_and_term` that\n",
    "# works with a real completed_courses.csv at data_dir.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timezone\n",
    "import warnings\n",
    "import json\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def clean_nan_columns(a: np.ndarray) -> np.ndarray:\n",
    "    a = np.asarray(a, float).copy()\n",
    "    m = np.nanmean(a, axis=0)\n",
    "    i = np.isnan(a)\n",
    "    a[i] = m[np.nonzero(i)[1]]\n",
    "    return a\n",
    "\n",
    "def makepreds(vals):\n",
    "\n",
    "    #need to hand clean data first\n",
    "    data = vals.T.values\n",
    "\n",
    "    data = clean_nan_columns(data)\n",
    "\n",
    "    num_depts = data.shape[1]\n",
    "    f_cnt = 3\n",
    "    feats = np.zeros((data.shape[0], f_cnt), dtype=np.float32)\n",
    "    ytrue = np.zeros((data.shape[0]), dtype=np.float32)\n",
    "    preds = []\n",
    "\n",
    "    for d in range(num_depts):\n",
    "\n",
    "        for n in range(f_cnt):\n",
    "            for m in range(f_cnt,data.shape[0]):\n",
    "                #print(f\"OPERATION: ln ( {data[m, n]} / {data[m-n, n]} )\")\n",
    "                #print(f\"OPERATION: m= {m}, n={n}\")\n",
    "                feats[m, n] = np.log(data[m, d]/data[m-n-1, d])\n",
    "\n",
    "        for m in range(data.shape[0]-1):\n",
    "            ytrue[m] = np.log(data[m+1, d]/data[m, d])\n",
    "\n",
    "        X = feats[f_cnt:-1]\n",
    "        y = ytrue[f_cnt:-1]\n",
    "\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        pred = lr.predict(feats[-1:,:])\n",
    "\n",
    "        #logical fail safe! not for the long term, only for\n",
    "        #short term product assurance, and not Logan Kelsch\n",
    "        #can validate this only appeared once but visually\n",
    "        #destroys the hook of this ML!!!!! ask Logan about it!\n",
    "        loc_mean = np.mean(data[:,d])\n",
    "        min_range = min(data[-1,d], loc_mean)\n",
    "        max_range = max(data[-1,d], loc_mean)\n",
    "        if(pred < min_range-0.5 or pred > max_range+0.5):\n",
    "            pred = loc_mean\n",
    "\n",
    "        #append and get out of here goodness 5:53am\n",
    "        preds.append(np.exp(pred)*data[-1:,d])\n",
    "\n",
    "    return np.array(preds)\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "GRADE_RANK = {\n",
    "    \"A+\": 4.33, \"A\": 4, \"A-\": 3.67,\n",
    "    \"B+\": 3.33,  \"B\": 3,  \"B-\": 2.67,\n",
    "    \"C+\": 2.33,  \"C\": 2,  \"C-\": 1.67,\n",
    "    \"D+\": 1.33,  \"D\": 1,  \"D-\": 0.67,\n",
    "    \"F\": 0\n",
    "}\n",
    "\n",
    "TERM_ORDER = {\"Winter\": 0, \"Spring\": 1, \"Summer\": 2, \"Fall\": 3}\n",
    "TERMS_SEQ   = [\"Winter\", \"Spring\", \"Summer\", \"Fall\"]  # for next-term inference\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def _term_sort_key(term: str):\n",
    "    \"\"\"\n",
    "    Convert a term string like 'Spring2024' into a tuple for sorting: (year, season_order).\n",
    "    If parsing fails, put it at the end, preserving input order via 9999.\n",
    "    \"\"\"\n",
    "    if not isinstance(term, str):\n",
    "        return (9999, 9)\n",
    "    m = re.match(r\"([A-Za-z]+)\\s*([0-9]{4})\", term) or re.match(r\"([A-Za-z]+)([0-9]{4})\", term)\n",
    "    if not m:\n",
    "        return (9999, 9)\n",
    "    season, year = m.group(1), int(m.group(2))\n",
    "    season_key = TERM_ORDER.get(season.capitalize(), 9)\n",
    "    return (year, season_key)\n",
    "\n",
    "def _parse_term(term: str):\n",
    "    m = re.match(r\"([A-Za-z]+)\\s*([0-9]{4})\", term) or re.match(r\"([A-Za-z]+)([0-9]{4})\", term)\n",
    "    if not m:\n",
    "        return None, None\n",
    "    return m.group(1).capitalize(), int(m.group(2))\n",
    "\n",
    "def _next_term_label(last_term: str) -> str:\n",
    "    season, year = _parse_term(last_term)\n",
    "    if season is None:\n",
    "        # fallback: append '+' if unknown format\n",
    "        return f\"{last_term}+1\"\n",
    "    idx = TERMS_SEQ.index(season) if season in TERMS_SEQ else 1\n",
    "    if idx == len(TERMS_SEQ) - 1:  # Fall -> Winter next year\n",
    "        return f\"{TERMS_SEQ[0]}{year + 1}\"\n",
    "    else:\n",
    "        return f\"{TERMS_SEQ[idx + 1]}{year}\"\n",
    "\n",
    "def _grade_to_numeric(g):\n",
    "    if pd.isna(g):\n",
    "        return np.nan\n",
    "    g = str(g).strip()\n",
    "    return GRADE_RANK.get(g, np.nan)\n",
    "\n",
    "\n",
    "def dyn_agg_gpa_forecasting(\n",
    "    completed_csv_path: str = None,\n",
    "    df_completed: pd.DataFrame = None,\n",
    "    courses_csv_path: str = \"../umbc_data/csv/courses.csv\",\n",
    "    agg: str = \"department\",                 # \"department\" | \"course_in_department\"\n",
    "    dept_letter: str | None = 'Z'           # when agg == \"course_in_department\", e.g., \"C\" or \"B\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build time series, predict next term, and return JSON for frontend.\n",
    "    - Always includes an OVERALL/UNIVERSITY series.\n",
    "    - agg=\"department\": rows are dept letters ('C','B'), averaged per term.\n",
    "    - agg=\"course_in_department\": filter to dept_letter and rows are course IDs, averaged per term.\n",
    "\n",
    "    Returns: forecast_json (dict) with meta + series (history + dashed forecast segment)\n",
    "    \"\"\"\n",
    "    # ---- Load data ----\n",
    "    if df_completed is None:\n",
    "        if completed_csv_path is None or not os.path.exists(completed_csv_path):\n",
    "            raise FileNotFoundError(\"Provide completed_courses.csv or df_completed.\")\n",
    "        df_completed = pd.read_csv(\n",
    "            completed_csv_path,\n",
    "            dtype={\":END_ID(Course)\": \"string\", \"term\": \"string\", \"grade\": \"string\"}\n",
    "        )\n",
    "    if not os.path.exists(courses_csv_path):\n",
    "        raise FileNotFoundError(courses_csv_path)\n",
    "    df_courses = pd.read_csv(\n",
    "        courses_csv_path,\n",
    "        dtype={\"id:ID(Course)\": \"string\", \"name\": \"string\", \"department\": \"string\"}\n",
    "    )\n",
    "\n",
    "    # ---- Prepare base long table ----\n",
    "    df = df_completed.dropna(subset=[\":END_ID(Course)\", \"grade\", \"term\"]).copy()\n",
    "    df[\":END_ID(Course)\"] = df[\":END_ID(Course)\"].astype(str)\n",
    "    df[\"dept_letter\"] = df[\":END_ID(Course)\"].str.slice(0, 1)\n",
    "    # level is 6th char (index 5); guard short strings\n",
    "    df[\"level_digit\"] = df[\":END_ID(Course)\"].str.slice(5, 6).str.extract(r\"(\\d)\").fillna(\"0\").astype(int)\n",
    "    df[\"grade_numeric\"] = df[\"grade\"].apply(_grade_to_numeric)\n",
    "\n",
    "    # ---- Department title map from courses.csv (first match wins) ----\n",
    "    # Example: for 'C' → \"Computer Science\", for 'B' → \"Biology\"\n",
    "    df_courses[\"dept_letter\"] = df_courses[\"id:ID(Course)\"].astype(str).str.slice(0, 1)\n",
    "    dept_titles = (\n",
    "        df_courses.dropna(subset=[\"dept_letter\", \"department\"])\n",
    "                  .drop_duplicates(subset=[\"dept_letter\"])\n",
    "                  .set_index(\"dept_letter\")[\"department\"]\n",
    "                  .to_dict()\n",
    "    )\n",
    "\n",
    "    # ---- Aggregation selection → build plot_wide (rows × terms), labels, metadata ----\n",
    "    if dept_letter not in ['B','C']:\n",
    "        grouped = (\n",
    "            df.groupby([\"dept_letter\", \"term\"], as_index=False)\n",
    "              .agg(avg_grade=(\"grade_numeric\", \"mean\"), count=(\"grade_numeric\", \"size\"))\n",
    "        )\n",
    "        ordered_terms = sorted(grouped[\"term\"].unique(), key=_term_sort_key)\n",
    "        plot_wide = (\n",
    "            grouped.pivot(index=\"dept_letter\", columns=\"term\", values=\"avg_grade\")\n",
    "                   .reindex(columns=ordered_terms)\n",
    "        )\n",
    "        row_labels = plot_wide.index.tolist()\n",
    "        # Titles for each row (department)\n",
    "        row_titles = {dl: dept_titles.get(dl, f\"Dept {dl}\") for dl in row_labels}\n",
    "        row_kind = \"department\"\n",
    "        row_course_map = {}  # not used in this mode\n",
    "\n",
    "    elif dept_letter in ['B','C']:\n",
    "        if not dept_letter:\n",
    "            raise ValueError(\"Provide dept_letter (e.g., 'C' or 'B') when agg='course_in_department'.\")\n",
    "        df_f = df.loc[df[\"dept_letter\"] == dept_letter].copy()\n",
    "        if df_f.empty:\n",
    "            raise ValueError(f\"No rows found for department letter '{dept_letter}'.\")\n",
    "        grouped = (\n",
    "            df_f.groupby([\":END_ID(Course)\", \"term\"], as_index=False)\n",
    "                .agg(avg_grade=(\"grade_numeric\", \"mean\"), count=(\"grade_numeric\", \"size\"))\n",
    "        )\n",
    "        ordered_terms = sorted(grouped[\"term\"].unique(), key=_term_sort_key)\n",
    "        plot_wide = (\n",
    "            grouped.pivot(index=\":END_ID(Course)\", columns=\"term\", values=\"avg_grade\")\n",
    "                   .reindex(columns=ordered_terms)\n",
    "        )\n",
    "        row_labels = plot_wide.index.tolist()  # course IDs\n",
    "        # Map course_id -> (course_name, department_title)\n",
    "        course_meta = (\n",
    "            df_courses.set_index(\"id:ID(Course)\")[[\"name\", \"department\"]]\n",
    "                      .to_dict(orient=\"index\")\n",
    "        )\n",
    "        row_titles = {\n",
    "            cid: course_meta.get(cid, {}).get(\"name\", cid) for cid in row_labels\n",
    "        }\n",
    "        row_course_map = {\n",
    "            cid: {\n",
    "                \"course_id\": cid,\n",
    "                \"course_name\": course_meta.get(cid, {}).get(\"name\"),\n",
    "                \"department_title\": course_meta.get(cid, {}).get(\"department\"),\n",
    "                \"department_letter\": dept_letter,\n",
    "            }\n",
    "            for cid in row_labels\n",
    "        }\n",
    "        row_kind = \"course\"\n",
    "    else:\n",
    "        raise ValueError(\"agg must be 'department' or 'course_in_department'.\")\n",
    "\n",
    "    # ---- Overall / University series (one row) ----\n",
    "    overall = (\n",
    "        df.groupby(\"term\", as_index=False)\n",
    "          .agg(avg_grade=(\"grade_numeric\", \"mean\"))\n",
    "          .set_index(\"term\")\n",
    "    )\n",
    "    # Align to the same term set\n",
    "    overall = overall.reindex(ordered_terms)\n",
    "    overall_wide = pd.DataFrame([overall[\"avg_grade\"].values], index=[\"UNIV\"], columns=ordered_terms)\n",
    "\n",
    "    # ---- Predictions (your makepreds) ----\n",
    "    preds_main = makepreds(plot_wide)                     # shape (rows,)\n",
    "    preds_overall = makepreds(overall_wide)               # shape (1,)\n",
    "\n",
    "    # Next term\n",
    "    last_term = ordered_terms[-1] if ordered_terms else \"Spring2025\"\n",
    "    next_term = _next_term_label(last_term)\n",
    "\n",
    "    # ---- Build JSON series for main rows ----\n",
    "    series = []\n",
    "    for i, key in enumerate(plot_wide.index.tolist()):\n",
    "        row_vals = plot_wide.iloc[i]\n",
    "        history = [{\"term\": str(t), \"value\": float(v), \"isPred\": False}\n",
    "                   for t, v in row_vals.items() if pd.notna(v)]\n",
    "        pred_val = float(preds_main[i]) if i < len(preds_main) and pd.notna(preds_main[i]) else None\n",
    "        forecast_segment = (\n",
    "            [{\"term\": str(last_term), \"value\": history[-1][\"value\"], \"isPred\": False},\n",
    "             {\"term\": next_term, \"value\": pred_val, \"isPred\": True}]\n",
    "        ) if history and pred_val is not None else []\n",
    "\n",
    "        entry = {\n",
    "            \"key\": str(key),\n",
    "            \"kind\": row_kind,  # \"department\" or \"course\"\n",
    "            \"title\": row_titles.get(key, str(key)),\n",
    "            \"history\": history,\n",
    "            \"forecast_segment\": forecast_segment,\n",
    "            \"next_point\": ({\"term\": next_term, \"value\": pred_val, \"isPred\": True} if pred_val is not None else None),\n",
    "        }\n",
    "        # attach metadata depending on mode\n",
    "        if row_kind == \"department\":\n",
    "            entry[\"department_letter\"] = str(key)\n",
    "            entry[\"department_title\"] = row_titles.get(key, f\"Dept {key}\")\n",
    "        else:\n",
    "            entry.update(row_course_map.get(key, {}))\n",
    "        series.append(entry)\n",
    "\n",
    "    # ---- Add OVERALL / UNIVERSITY series ----\n",
    "    ov_vals = overall_wide.iloc[0]\n",
    "    ov_hist = [{\"term\": str(t), \"value\": float(v), \"isPred\": False} for t, v in ov_vals.items() if pd.notna(v)]\n",
    "    ov_pred = float(preds_overall[0]) if preds_overall is not None and len(preds_overall) else None\n",
    "    ov_seg = (\n",
    "        [{\"term\": str(last_term), \"value\": ov_hist[-1][\"value\"], \"isPred\": False},\n",
    "         {\"term\": next_term, \"value\": ov_pred, \"isPred\": True}]\n",
    "    ) if ov_hist and ov_pred is not None else []\n",
    "    series.append({\n",
    "        \"key\": \"UNIV\",\n",
    "        \"kind\": \"overall\",\n",
    "        \"title\": \"University\",\n",
    "        \"history\": ov_hist,\n",
    "        \"forecast_segment\": ov_seg,\n",
    "        \"next_point\": ({\"term\": next_term, \"value\": ov_pred, \"isPred\": True} if ov_pred is not None else None),\n",
    "    })\n",
    "\n",
    "    # ---- Meta + payload ----\n",
    "    forecast_json = {\n",
    "        \"meta\": {\n",
    "            \"metric\": \"avg_gpa\",\n",
    "            \"terms\": [str(t) for t in ordered_terms],\n",
    "            \"next_term\": next_term,\n",
    "            \"units\": \"GPA (0–4.33)\",\n",
    "            \"agg\": agg,\n",
    "            \"dept_letter\": dept_letter,\n",
    "            \"generated_at\": datetime.now(timezone.utc).isoformat()\n",
    "        },\n",
    "        \"series\": series\n",
    "    }\n",
    "    return forecast_json\n",
    "\n",
    "\n",
    "\n",
    "# Point this to your actual CSV\n",
    "forecast_json = dyn_agg_gpa_forecasting(\n",
    "    completed_csv_path=\"../umbc_data/csv/completed_courses.csv\",\n",
    "    dept_letter='C'\n",
    ")\n",
    "\n",
    "# If you want to see the JSON:\n",
    "import json\n",
    "print(json.dumps(forecast_json, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
